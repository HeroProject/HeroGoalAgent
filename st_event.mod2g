use dialogflow as knowledge.
use script as knowledge.
use dialogflow as actionspec.
use 'recognitionAndRepairePipeline/startAnswerRecognition' as module.
use 'recognitionAndRepairePipeline/retrieveInput' as module.
use 'recognitionAndRepairePipeline/repair' as module.
use 'recognitionAndRepairePipeline/processAnswer' as module.
use 'stateLogic/performStateTransition' as module.

module st_event {
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%% Percept and event processing      %%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	%forall percept(intent(Intent, Params)), not(bel(intent(Intent, Params)))
		%do insert(intent(Intent, Params)) + log(insertIntent(Intent, Params)).

	% NAO event percepts
	forall percept(event(E)), not(bel(event(E)))
		do insert(event(E)).
	forall bel(event(E)), not(percept(event(E)))
		do delete(event(E)).
		
	% Handling of event waiting logic...
	% ... for NAO events
	if bel(event(E), waitingForEvent(E))
		then delete(waitingForEvent(E)).
	
	% Handling timeouts
	if percept(timer(S, _)), not(bel(timeout(S)))
		then insert(timeout(S)).
	if bel(timeout(S)), not(percept(timer(S, _)))
		then delete(timeout(S)).
		
	%Audio recording percepts
	if percept(audioRecording(FileName)), bel(currentState(S), waitingForAudio)
		then delete(waitingForAudio) + insert(audioRecording(S, FileName)).
	
	%Emotion detection percepts
	if percept(emotionDetected(Emotion)), bel(currentState(S))
		then insert(emotion(S, Emotion)) + delete(waitingForEmotion) + log(Emotion) + stopWatching.
	
	%% Dialogflow tweaks %%
	% Adding 1000ms additional waiting time after stop streaming audio to dialogflow.
	if bel(currentTopic(T), currentState(S), state(T, S, question), timeout(S), waitingForAnswer, currentInputModality(speech))
		then stopListening + starttimer(dialogflow, 1000, 1000).
		
	% Cut of listening if user already answered something that did not match anything.
	if percept(speechText(Text)), bel(currentState(S), waitingForAnswer, currentInputModality(speech), currentAttempt(CurrentAttempt))
		then stopListening + canceltimer(S) + canceltimer(dialogflow) + insert(timeout(dialogflow), speechText(S, CurrentAttempt, Text)).

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%% Recognition and Repair            %%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	%%% SPEECH %%%
	% Dialogflow produces an input. Retrieve answer.
	if percept(intent(Intent, Params)), bel(currentTopic(T), currentState(S), state(T, S, question), currentInputModality(speech), waitingForAnswer)
		then retrieveInput(T, S, Intent, Params).
			
	% Dialogflow does not produce an input. Try a repair action.
	if bel(currentTopic(T), currentState(S), state(T, S, question), waitingForAnswer, timeout(dialogflow), currentInputModality(speech))
		then repair(T, S).
	
	%%% TOUCH %%%
	% An answer has been selected. Retrieve answer.
	if bel(currentTopic(T), currentState(S), state(T, S, question), waitingForAnswer, feetBumperEventAnswer(Intent))
		then retrieveInput(T, S, Intent, []).
	
	% No answer has been selected. Try a repair action.
	if bel(currentTopic(T), currentState(S), state(T, S, question), timeout(S), waitingForAnswer, currentInputModality(touch))
		then repair(T, S).
		
	%%% AUDIO RECORDING %%%
	% When timeout occurs while waiting for audio the audio recording is completed. Stop listening (and waiting for audio input). 
	if bel(currentTopic(Topic), currentState(S), state(Topic, S, audioInput), timeout(S), waitingForAudio)
		then stopListening + disableRecording.

	%%% EMOTION RECOGNITION %%%	
	% When timeout occurs while waiting for emotion, emotion detection is stopped.
	if bel(currentTopic(Topic), currentState(S), state(Topic, S, emotion), timeout(S), waitingForEmotion, not(emotion(S,_)))
		then stopWatching + insert(emotion(S, 'fail')) + delete(waitingForEmotion).
		
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%% Answer processing			      %%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	%Given an answer(T, S, Ans, Details) and the type of question (yesno, input, branch, quiz) the answers should be processed differently.
	if bel(currentTopic(T), currentState(S), answer(T,S, Ans, _), not(answerProcessed))
		then processAnswer(T, S, Ans).
		
	% If the state is a branching point, retrieve the decision and insert that as the nextCondition.
	if bel(currentTopic(T), currentState(S), state(T, S, branchingPoint), getBranchingPointDecision([T, S], Decision), nextCondition(Con))
		then delete(nextCondition(Con)) + insert(nextCondition(Decision)).
		
	% If an emotion is expected and present, set that as the next condition.
	if bel(currentTopic(T), currentState(S), state(T, S, emotion), emotion(S,Emotion), nextCondition(Con), not(Con=Emotion))
		then delete(nextCondition(Con)) + insert(nextCondition(Emotion)).

		
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%% Start recognition for answers, audio, and emotions  %%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	% Question
	if bel(currentTopic(T), currentState(S), state(T, S, question), eventsCompleted, not(waitingForAnswer), not(answer(T, S, _, _)))
		then startAnswerRecognition(T, S).
		
	% Audiorecording
	if bel(currentTopic(T), currentState(S), state(T, S, audioInput), eventsCompleted, not(waitingForAudio), not(audioRecording(S,_)),
		keyListValues(T, S, recordTime, RT))
		then enableRecording + startListening + starttimer(S, RT, RT) + insert(waitingForAudio).
	
	% Emotion
	if bel(currentTopic(T), currentState(S), state(T, S, emotion), eventsCompleted, not(waitingForEmotion), not(emotion(S,_)))
		then startWatching + starttimer(S, 6000, 6000) + insert(waitingForEmotion).

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%%% State transition handling            %%%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	% If state has been completed,  
	if bel(currentTopic(T), completed(S), nextCondition(C)) then performStateTransition(T, S, C).
	
}